"""
ä¸œå´è¯åˆ¸ç ”æŠ¥å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å››å±‚å¼‚å¸¸æ£€æµ‹ä½“ç³»å¯¹ç ”æŠ¥è¿›è¡Œç»¼åˆå¼‚å¸¸æ£€æµ‹
"""

import sys
import os
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.anomaly_detection.ensemble_detector import get_ensemble_detector
from src.utils.logger import get_logger

logger = get_logger(__name__)


def create_sample_report_data():
    """
    åˆ›å»ºç¤ºä¾‹ç ”æŠ¥æ•°æ®
    
    Returns:
        ç¤ºä¾‹ç ”æŠ¥æ•°æ®åˆ—è¡¨
    """
    sample_reports = [
        {
            'text': """
            ä¸œå´è¯åˆ¸ç ”æŠ¥ï¼šæŸç§‘æŠ€è‚¡æŠ•èµ„ä»·å€¼åˆ†æž
            
            åŸºäºŽæˆ‘ä»¬çš„æ·±åº¦è°ƒç ”ï¼Œè¯¥å…¬å¸Q3ä¸šç»©è¶…é¢„æœŸå¢žé•¿35%ï¼Œè¥æ”¶è¾¾åˆ°85äº¿å…ƒï¼Œ
            å‡€åˆ©æ¶¦12.3äº¿å…ƒï¼ŒåŒæ¯”å¢žé•¿28%ã€‚å…¬å¸åœ¨AIèŠ¯ç‰‡é¢†åŸŸçš„æŠ€æœ¯çªç ´å€¼å¾—å…³æ³¨ã€‚
            
            æ ¸å¿ƒæŠ•èµ„é€»è¾‘ï¼š
            1. æŠ€æœ¯æŠ¤åŸŽæ²³æ·±åŽšï¼ŒAIèŠ¯ç‰‡æ€§èƒ½é¢†å…ˆåŒè¡Œ20%
            2. ä¸‹æ¸¸éœ€æ±‚æ—ºç››ï¼Œè®¢å•é¥±æ»¡è‡³æ˜Žå¹´Q2
            3. æ¯›åˆ©çŽ‡æŒç»­æå‡ï¼Œè¾¾åˆ°43.2%
            4. ç®¡ç†å±‚æ‰§è¡ŒåŠ›å¼ºï¼Œæˆ˜ç•¥æ¸…æ™°
            
            é£Žé™©æç¤ºï¼š
            1. è¡Œä¸šç«žäº‰åŠ å‰§é£Žé™©
            2. æŠ€æœ¯è¿­ä»£é£Žé™©
            3. ä¸‹æ¸¸éœ€æ±‚æ³¢åŠ¨é£Žé™©
            
            ç»¼åˆè€ƒè™‘ï¼Œæˆ‘ä»¬ç»´æŒ"ä¹°å…¥"è¯„çº§ï¼Œç›®æ ‡ä»·65å…ƒï¼Œè¾ƒå½“å‰ä»·æ ¼æœ‰30%ä¸Šæ¶¨ç©ºé—´ã€‚
            """,
            'publication_time': datetime.now() - timedelta(days=1),
            'author': 'å¼ ä¸‰',
            'stock_codes': ['000001'],
            'rating': 'ä¹°å…¥',
            'target_prices': {'000001': 65.0},
            'industry': 'ç§‘æŠ€',
            'publication_date': datetime.now() - timedelta(days=1)
        },
        {
            'text': """
            ç´§æ€¥è°ƒç ”æŠ¥å‘Šï¼šæŸç§‘æŠ€è‚¡é‡å¤§å˜åŒ–
            
            æ®å¯é æ¶ˆæ¯ï¼Œè¯¥å…¬å¸å³å°†å‘å¸ƒé©å‘½æ€§äº§å“ï¼Œé¢„è®¡å°†å¸¦æ¥å·¨å¤§å˜é©ã€‚
            å†…éƒ¨äººå£«é€éœ²ï¼Œæ–°äº§å“æ€§èƒ½è¶…è¶Šå¸‚åœºé¢„æœŸæ•°å€ã€‚
            
            åŸºäºŽæœ€æ–°èŽ·å¾—çš„ç‹¬å®¶ä¿¡æ¯ï¼Œæˆ‘ä»¬é¢„è®¡ï¼š
            - Q4è¥æ”¶å°†æš´æ¶¨200%
            - æ˜Žå¹´å‡€åˆ©æ¶¦å¢žé•¿500%
            - è‚¡ä»·æœ‰æœ›ç¿»å€
            
            ä½†æ˜¯æˆ‘ä»¬åŒæ—¶æ³¨æ„åˆ°ï¼Œå…¬å¸è¿‘æœŸé¢ä¸´ç›‘ç®¡åŽ‹åŠ›ï¼Œä¸šåŠ¡å‘å±•å­˜åœ¨ä¸ç¡®å®šæ€§ã€‚
            è´¢åŠ¡æ•°æ®æ˜¾ç¤ºç›ˆåˆ©èƒ½åŠ›ä¸‹é™ï¼ŒçŽ°é‡‘æµç´§å¼ ã€‚
            
            ç»¼åˆåˆ¤æ–­ï¼Œæˆ‘ä»¬ç»™äºˆ"å¼ºçƒˆæŽ¨è"è¯„çº§ï¼Œç›®æ ‡ä»·120å…ƒã€‚
            åŒæ—¶æé†’æŠ•èµ„è€…æ³¨æ„é£Žé™©ï¼Œå»ºè®®è°¨æ…ŽæŠ•èµ„ã€‚
            """,
            'publication_time': datetime.now(),
            'author': 'æŽå››',
            'stock_codes': ['000001'],
            'rating': 'å¼ºçƒˆæŽ¨è',
            'target_prices': {'000001': 120.0},
            'industry': 'ç§‘æŠ€',
            'publication_date': datetime.now()
        }
    ]
    
    return sample_reports


def create_sample_market_data(detector):
    """
    åˆ›å»ºç¤ºä¾‹å¸‚åœºæ•°æ®
    
    Args:
        detector: é›†æˆæ£€æµ‹å™¨å®žä¾‹
    """
    # æ·»åŠ ç¤ºä¾‹å¸‚åœºæ•°æ®
    base_date = datetime.now() - timedelta(days=30)
    base_price = 50.0
    
    for i in range(30):
        date = base_date + timedelta(days=i)
        
        # æ¨¡æ‹Ÿä»·æ ¼æ³¢åŠ¨
        price_change = (i - 15) * 0.5 + np.random.normal(0, 1)
        close_price = base_price + price_change
        open_price = close_price + np.random.normal(0, 0.5)
        high_price = max(open_price, close_price) + abs(np.random.normal(0, 0.3))
        low_price = min(open_price, close_price) - abs(np.random.normal(0, 0.3))
        volume = int(10000000 + np.random.normal(0, 2000000))
        
        detector.market_detector.add_market_data(
            stock_code='000001',
            date=date,
            open_price=open_price,
            close_price=close_price,
            high_price=high_price,
            low_price=low_price,
            volume=max(volume, 1000000)  # ç¡®ä¿æˆäº¤é‡ä¸ºæ­£
        )


def create_sample_market_events(detector):
    """
    åˆ›å»ºç¤ºä¾‹å¸‚åœºäº‹ä»¶
    
    Args:
        detector: é›†æˆæ£€æµ‹å™¨å®žä¾‹
    """
    # æ·»åŠ å¸‚åœºäº‹ä»¶
    detector.behavioral_detector.add_market_event(
        event_time=datetime.now() - timedelta(hours=6),
        event_type='earnings',
        description='ç§‘æŠ€æ¿å—è´¢æŠ¥å­£å¼€å§‹',
        affected_stocks=['000001']
    )
    
    detector.behavioral_detector.add_market_event(
        event_time=datetime.now() - timedelta(days=2),
        event_type='policy',
        description='AIäº§ä¸šæ”¿ç­–åˆ©å¥½å‘å¸ƒ',
        affected_stocks=['000001']
    )


def demonstrate_single_detection():
    """
    æ¼”ç¤ºå•ä¸ªç ”æŠ¥çš„å¼‚å¸¸æ£€æµ‹
    """
    print("\n" + "="*80)
    print("ä¸œå´è¯åˆ¸ç ”æŠ¥å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæ¼”ç¤º")
    print("="*80)
    
    # èŽ·å–é›†æˆæ£€æµ‹å™¨
    detector = get_ensemble_detector()
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    import numpy as np
    create_sample_market_data(detector)
    create_sample_market_events(detector)
    
    # èŽ·å–ç¤ºä¾‹ç ”æŠ¥
    sample_reports = create_sample_report_data()
    
    print(f"\nðŸ“Š å¼€å§‹æ£€æµ‹ {len(sample_reports)} ä¸ªç ”æŠ¥æ ·æœ¬")
    
    for i, report in enumerate(sample_reports):
        print(f"\n{'='*60}")
        print(f"ðŸ“„ ç ”æŠ¥ {i+1}: {report['author']} - {report['rating']}")
        print(f"ðŸ“… å‘å¸ƒæ—¶é—´: {report['publication_time'].strftime('%Y-%m-%d %H:%M')}")
        print(f"ðŸ“ˆ è‚¡ç¥¨ä»£ç : {', '.join(report['stock_codes'])}")
        print(f"ðŸ“ æ–‡æœ¬é•¿åº¦: {len(report['text'])} å­—ç¬¦")
        
        # æ‰§è¡Œå¼‚å¸¸æ£€æµ‹
        result = detector.detect_anomalies(report)
        
        # æ˜¾ç¤ºæ£€æµ‹ç»“æžœ
        print(f"\nðŸ” å¼‚å¸¸æ£€æµ‹ç»“æžœ:")
        print(f"   æ€»ä½“å¼‚å¸¸åˆ†æ•°: {result['overall_anomaly_score']:.3f}")
        print(f"   å¼‚å¸¸ç­‰çº§: {result['anomaly_level']}")
        print(f"   æ˜¯å¦å¼‚å¸¸: {'æ˜¯' if result['is_anomaly'] else 'å¦'}")
        
        # æ˜¾ç¤ºå„å±‚æ£€æµ‹ç»“æžœ
        print(f"\nðŸ“‹ åˆ†å±‚æ£€æµ‹åˆ†æ•°:")
        for layer, score in result['layer_scores'].items():
            emoji = "âš ï¸" if score > 0.5 else "âœ…" if score < 0.3 else "âš¡"
            print(f"   {emoji} {layer:12}: {score:.3f}")
        
        # æ˜¾ç¤ºå¼‚å¸¸å±‚
        if result['layer_anomalies']:
            print(f"\nðŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸çš„å±‚çº§:")
            for layer in result['layer_anomalies']:
                print(f"   â€¢ {layer}")
        
        # æ˜¾ç¤ºå¼‚å¸¸æ¨¡å¼
        pattern = result['anomaly_pattern']
        if pattern['pattern_description'] != 'æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚å¸¸':
            print(f"\nðŸ” å¼‚å¸¸æ¨¡å¼åˆ†æž:")
            print(f"   ä¸»è¦å¼‚å¸¸ç±»åž‹: {pattern['primary_anomaly_type']}")
            print(f"   é£Žé™©ç­‰çº§: {pattern['risk_level']}")
            print(f"   æ¨¡å¼æè¿°: {pattern['pattern_description']}")
        
        # æ˜¾ç¤ºå»ºè®®
        if result['recommendations']:
            print(f"\nðŸ’¡ å¤„ç†å»ºè®®:")
            for rec in result['recommendations'][:3]:  # æ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                print(f"   â€¢ {rec}")
        
        # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ï¼ˆå¦‚æžœæœ‰ï¼‰
        if 'detection_errors' in result:
            print(f"\nâš ï¸  æ£€æµ‹è¿‡ç¨‹ä¸­çš„é”™è¯¯:")
            for error in result['detection_errors']:
                print(f"   â€¢ {error}")


def demonstrate_batch_detection():
    """
    æ¼”ç¤ºæ‰¹é‡å¼‚å¸¸æ£€æµ‹
    """
    print(f"\n{'='*60}")
    print("ðŸ“Š æ‰¹é‡å¼‚å¸¸æ£€æµ‹æ¼”ç¤º")
    print(f"{'='*60}")
    
    detector = get_ensemble_detector()
    sample_reports = create_sample_report_data()
    
    # æ›´æ–°åŽ†å²æ•°æ®
    print("ðŸ“ˆ æ›´æ–°åŽ†å²æ•°æ®...")
    detector.update_historical_data(sample_reports)
    
    # æ‰¹é‡æ£€æµ‹
    print("ðŸ” æ‰§è¡Œæ‰¹é‡æ£€æµ‹...")
    batch_results = detector.batch_detect(sample_reports)
    
    # ç»Ÿè®¡ç»“æžœ
    anomaly_count = sum(1 for r in batch_results if r.get('is_anomaly', False))
    avg_score = np.mean([r.get('overall_anomaly_score', 0) for r in batch_results])
    
    print(f"\nðŸ“ˆ æ‰¹é‡æ£€æµ‹ç»Ÿè®¡:")
    print(f"   æ€»ç ”æŠ¥æ•°: {len(batch_results)}")
    print(f"   å¼‚å¸¸ç ”æŠ¥æ•°: {anomaly_count}")
    print(f"   å¼‚å¸¸æ¯”ä¾‹: {anomaly_count/len(batch_results)*100:.1f}%")
    print(f"   å¹³å‡å¼‚å¸¸åˆ†æ•°: {avg_score:.3f}")
    
    # æŒ‰å¼‚å¸¸ç­‰çº§åˆ†ç±»
    level_counts = {}
    for result in batch_results:
        level = result.get('anomaly_level', 'NORMAL')
        level_counts[level] = level_counts.get(level, 0) + 1
    
    print(f"\nðŸ“Š å¼‚å¸¸ç­‰çº§åˆ†å¸ƒ:")
    for level, count in sorted(level_counts.items()):
        print(f"   {level:8}: {count} ä¸ª")


def demonstrate_system_status():
    """
    æ¼”ç¤ºç³»ç»ŸçŠ¶æ€æŸ¥çœ‹
    """
    print(f"\n{'='*60}")
    print("ðŸ“Š ç³»ç»ŸçŠ¶æ€æ¼”ç¤º")
    print(f"{'='*60}")
    
    detector = get_ensemble_detector()
    summary = detector.get_detection_summary()
    
    print("âš™ï¸  æ£€æµ‹å™¨é…ç½®:")
    weights = summary['ensemble_config']['anomaly_weights']
    for detector_type, weight in weights.items():
        print(f"   {detector_type:25}: {weight:.2f}")
    
    print("\nðŸ“ˆ æ£€æµ‹å™¨çŠ¶æ€:")
    status = summary['detectors_status']
    
    if 'statistical' in status:
        stat_status = status['statistical']
        print(f"   ç»Ÿè®¡æ£€æµ‹å™¨:")
        print(f"     åŽ†å²æ–‡æ¡£æ•°: {stat_status.get('total_documents', 0)}")
        print(f"     è¯æ±‡è¡¨å¤§å°: {stat_status.get('vocabulary_size', 0)}")
    
    if 'behavioral' in status:
        behav_status = status['behavioral']
        print(f"   è¡Œä¸ºæ£€æµ‹å™¨:")
        print(f"     åŽ†å²å‘å¸ƒæ•°: {behav_status.get('total_publications', 0)}")
        print(f"     è¦†ç›–è‚¡ç¥¨æ•°: {behav_status.get('unique_stocks', 0)}")
        print(f"     ä½œè€…æ•°é‡: {behav_status.get('unique_authors', 0)}")
    
    if 'market' in status:
        market_status = status['market']
        print(f"   å¸‚åœºæ£€æµ‹å™¨:")
        print(f"     è‚¡ç¥¨æ•°æ®: {market_status.get('total_stocks', 0)}")
        print(f"     é¢„æµ‹è®°å½•: {market_status.get('total_predictions', 0)}")


def main():
    """
    ä¸»å‡½æ•°
    """
    try:
        # æ¼”ç¤ºå•ä¸ªæ£€æµ‹
        demonstrate_single_detection()
        
        # æ¼”ç¤ºæ‰¹é‡æ£€æµ‹
        demonstrate_batch_detection()
        
        # æ¼”ç¤ºç³»ç»ŸçŠ¶æ€
        demonstrate_system_status()
        
        print(f"\n{'='*80}")
        print("âœ… æ¼”ç¤ºå®Œæˆï¼")
        print("ðŸ“š æ›´å¤šåŠŸèƒ½è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£")
        print("="*80)
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹å‡ºé”™: {str(e)}")
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {str(e)}")
        print("ðŸ’¡ è¯·æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…")


if __name__ == "__main__":
    main() 