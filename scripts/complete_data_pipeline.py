#!/usr/bin/env python3
"""
ä¸œå´è¯åˆ¸ç ”æŠ¥æ•°æ®è§£æå®Œæ•´æµç¨‹æ¼”ç¤º
æ ‡å‡†åŒ–çš„æ•°æ®å¤„ç†pipelineï¼Œé€‚ç”¨äºæ‰¹é‡å¤„ç†
"""

import sys
import json
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "tools"))

def print_step_header(step_num: int, step_name: str):
    """æ‰“å°æ­¥éª¤æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ­¥éª¤ {step_num}: {step_name}")
    print(f"{'='*60}")

def print_result_summary(data: Dict[str, Any]):
    """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
    basic_info = data.get('basic_info', {})
    core_content = data.get('core_content', {})
    stocks = data.get('recommended_stocks', [])
    
    print(f"\nâœ… **è§£æç»“æœæ‘˜è¦**:")
    print(f"   ğŸ“‹ ä¸»é¢˜: {basic_info.get('theme', 'æœªè¯†åˆ«')[:50]}...")
    print(f"   ğŸ“Š ç±»å‹: {basic_info.get('type', 'æœªè¯†åˆ«')}")
    print(f"   ğŸ“… æ—¥æœŸ: {basic_info.get('publish_date', 'æœªè¯†åˆ«')}")
    print(f"   ğŸ’¡ å»ºè®®: {basic_info.get('investment_advice', 'æœªè¯†åˆ«')}")
    print(f"   ğŸ”„ å˜åŒ–: {basic_info.get('has_changes', 'æœªè¯†åˆ«')}")
    print(f"   ğŸ“ˆ æ¨èè‚¡ç¥¨: {len(stocks)} åª")

def extract_key_stocks(data: Dict[str, Any]) -> List[Dict[str, str]]:
    """ä»è§£æç»“æœä¸­æå–å…³é”®è‚¡ç¥¨ä¿¡æ¯"""
    content = data.get('core_content', {}).get('investment_highlights', '')
    
    # ç®€å•çš„è‚¡ç¥¨åç§°æå–ï¼ˆåç»­å¯ä»¥ä¼˜åŒ–ï¼‰
    stock_keywords = [
        "ä¸‰èŠ±æ™ºæ§", "å®‡é€šå®¢è½¦", "æ°ç‘è‚¡ä»½", "é“é€šç§‘æŠ€", "è“æ€ç§‘æŠ€",
        "åç§¦ç§‘æŠ€", "ä¸Šæµ·æ¸¯æ¹¾", "ç€šè“ç¯å¢ƒ", "å®‰å…‹åˆ›æ–°", "äºšé¦™è‚¡ä»½"
    ]
    
    found_stocks = []
    for i, stock in enumerate(stock_keywords, 1):
        if stock in content:
            # æå–æ¿å—ä¿¡æ¯
            sector = "æœªåˆ†ç±»"
            if "ç”µæ–°" in content and stock == "ä¸‰èŠ±æ™ºæ§":
                sector = "ç”µæ–°"
            elif "æ±½è½¦" in content and stock == "å®‡é€šå®¢è½¦":
                sector = "æ±½è½¦"
            elif "æœºæ¢°" in content and stock == "æ°ç‘è‚¡ä»½":
                sector = "æœºæ¢°"
            elif "ç§‘æŠ€" in content and stock == "é“é€šç§‘æŠ€":
                sector = "æµ·å¤–ç§‘æŠ€"
            elif "ç”µå­" in content and stock == "è“æ€ç§‘æŠ€":
                sector = "ç”µå­"
            elif "å†›å·¥" in content and stock == "åç§¦ç§‘æŠ€":
                sector = "å†›å·¥"
            elif "å»ºæ" in content and stock == "ä¸Šæµ·æ¸¯æ¹¾":
                sector = "å»ºç­‘å»ºæ"
            elif "ç¯ä¿" in content and stock == "ç€šè“ç¯å¢ƒ":
                sector = "ç¯ä¿å…¬ç”¨"
            elif "å•†ç¤¾" in content and stock == "å®‰å…‹åˆ›æ–°":
                sector = "å•†ç¤¾"
            elif "åŒ–å·¥" in content and stock == "äºšé¦™è‚¡ä»½":
                sector = "èƒ½æºåŒ–å·¥"
            
            found_stocks.append({
                "åºå·": f"1.{i}",
                "æ¿å—": sector,
                "è‚¡ç¥¨åç§°": stock,
                "æ¨èç†ç”±": f"è¯¦è§{stock}æŠ•èµ„å»ºè®®"
            })
    
    return found_stocks

def complete_data_pipeline():
    """å®Œæ•´çš„æ•°æ®è§£ææµç¨‹æ¼”ç¤º"""
    
    print("ğŸš€ ä¸œå´è¯åˆ¸ç ”æŠ¥æ•°æ®è§£æå®Œæ•´æµç¨‹æ¼”ç¤º")
    print("="*60)
    print("ğŸ“‹ æµç¨‹è¯´æ˜ï¼šè¾“å…¥åŸå§‹JSON â†’ æ ¼å¼ä¿®å¤ â†’ å†…å®¹è§£æ â†’ ç»“æ„åŒ–è¾“å‡º")
    print("ğŸ¯ ç›®æ ‡ï¼šå»ºç«‹æ ‡å‡†åŒ–æ•°æ®å¤„ç†pipelineï¼Œæ”¯æŒæ‰¹é‡å¤„ç†")
    
    # æ­¥éª¤1: è¯»å–åŸå§‹æ•°æ®
    print_step_header(1, "è¯»å–åŸå§‹ç ”æŠ¥æ•°æ®")
    
    input_file = project_root / "user_data" / "json_files" / "dongwu_complete_fixed.json"
    if not input_file.exists():
        print(f"âŒ é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    with open(input_file, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
    
    print(f"âœ… æˆåŠŸè¯»å–åŸå§‹æ•°æ®")
    print(f"   ğŸ“„ æ–‡ä»¶: {input_file.name}")
    print(f"   ğŸ“Š æ•°æ®å¤§å°: {len(str(raw_data))} å­—ç¬¦")
    print(f"   ğŸ¢ åˆ¸å•†: {raw_data.get('metadata', {}).get('broker', 'æœªçŸ¥')}")
    
    # æ­¥éª¤2: ä½¿ç”¨å¢å¼ºç‰ˆé¢„å¤„ç†å™¨è§£æ
    print_step_header(2, "æ™ºèƒ½å†…å®¹è§£æ")
    
    try:
        from enhanced_report_preprocessor import EnhancedReportPreprocessor
        
        preprocessor = EnhancedReportPreprocessor()
        print("âœ… é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # å¤„ç†æ•°æ®
        processed_data = preprocessor.process_report(raw_data)
        print("âœ… æ•°æ®è§£æå®Œæˆ")
        
        # æ˜¾ç¤ºè§£æç»“æœæ‘˜è¦
        print_result_summary(processed_data)
        
    except Exception as e:
        print(f"âŒ è§£æè¿‡ç¨‹å‡ºé”™: {str(e)}")
        return
    
    # æ­¥éª¤3: æ•°æ®ä¼˜åŒ–å’Œæ¸…ç†
    print_step_header(3, "æ•°æ®ä¼˜åŒ–å’Œæ¸…ç†")
    
    # æå–å…³é”®è‚¡ç¥¨ä¿¡æ¯
    key_stocks = extract_key_stocks(processed_data)
    processed_data['key_stocks'] = key_stocks
    
    print(f"âœ… æå–åˆ° {len(key_stocks)} åªå…³é”®è‚¡ç¥¨")
    for stock in key_stocks:
        print(f"   ğŸ“ˆ {stock['è‚¡ç¥¨åç§°']} ({stock['æ¿å—']})")
    
    # ä¼˜åŒ–ä¸»é¢˜æå–ï¼ˆæˆªå–å‰100å­—ç¬¦ï¼‰
    if 'basic_info' in processed_data and 'theme' in processed_data['basic_info']:
        theme = processed_data['basic_info']['theme']
        if len(theme) > 100:
            processed_data['basic_info']['theme'] = theme[:100] + "..."
    
    print("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
    
    # æ­¥éª¤4: ç”Ÿæˆæ ‡å‡†åŒ–è¾“å‡º
    print_step_header(4, "ç”Ÿæˆæ ‡å‡†åŒ–è¾“å‡º")
    
    # åˆ›å»ºæœ€ç»ˆè¾“å‡ºç»“æ„
    final_output = {
        "report_metadata": {
            "report_id": processed_data.get('report_id'),
            "source_broker": "ä¸œå´è¯åˆ¸",
            "processing_time": datetime.now().isoformat(),
            "pipeline_version": "1.0",
            "data_quality_score": calculate_quality_score(processed_data)
        },
        "extracted_data": {
            "basic_info": processed_data.get('basic_info', {}),
            "core_content": processed_data.get('core_content', {}),
            "key_stocks": key_stocks,
            "risk_factors": extract_risk_factors(processed_data),
            "financial_metrics": extract_financial_metrics(processed_data)
        },
        "processing_status": {
            "format_fixed": True,
            "content_extracted": True,
            "stocks_identified": len(key_stocks) > 0,
            "ready_for_analysis": True
        }
    }
    
    # ä¿å­˜æ ‡å‡†åŒ–è¾“å‡º
    output_file = project_root / "user_data" / "json_files" / "dongwu_standardized_output.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ ‡å‡†åŒ–è¾“å‡ºå·²ä¿å­˜: {output_file.name}")
    
    # æ­¥éª¤5: ç”Ÿæˆå¤„ç†æŠ¥å‘Š
    print_step_header(5, "ç”Ÿæˆå¤„ç†æŠ¥å‘Š")
    
    generate_processing_report(final_output)
    
    print(f"\nğŸ‰ **æ•°æ®è§£ææµç¨‹å®Œæˆï¼**")
    print(f"ğŸ“Š è´¨é‡è¯„åˆ†: {final_output['report_metadata']['data_quality_score']}/100")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“ˆ å¯åˆ†æçŠ¶æ€: {'æ˜¯' if final_output['processing_status']['ready_for_analysis'] else 'å¦'}")

def calculate_quality_score(data: Dict[str, Any]) -> int:
    """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
    score = 0
    
    # åŸºæœ¬ä¿¡æ¯å®Œæ•´æ€§ (40åˆ†)
    basic_info = data.get('basic_info', {})
    if basic_info.get('theme'): score += 10
    if basic_info.get('type'): score += 10
    if basic_info.get('investment_advice'): score += 10
    if basic_info.get('publish_date'): score += 10
    
    # æ ¸å¿ƒå†…å®¹è´¨é‡ (40åˆ†)
    core_content = data.get('core_content', {})
    content_length = len(str(core_content))
    if content_length > 1000: score += 15
    elif content_length > 500: score += 10
    elif content_length > 200: score += 5
    
    if core_content.get('investment_highlights'): score += 10
    if core_content.get('risk_warnings'): score += 10
    if core_content.get('financial_forecast'): score += 5
    
    # ç»“æ„åŒ–ç¨‹åº¦ (20åˆ†)
    if data.get('recommended_stocks'): score += 10
    if len(str(data)) > 5000: score += 10  # ä¸°å¯Œåº¦
    
    return min(score, 100)

def extract_risk_factors(data: Dict[str, Any]) -> List[str]:
    """æå–é£é™©å› ç´ """
    risk_text = data.get('core_content', {}).get('risk_warnings', '')
    
    # ç®€å•çš„é£é™©å› ç´ æå–
    risk_keywords = [
        "å¸‚åœºé£é™©", "æ”¿ç­–é£é™©", "æŠ€æœ¯é£é™©", "ç»æµé£é™©", 
        "ç«äº‰é£é™©", "æ±‡ç‡é£é™©", "æµåŠ¨æ€§é£é™©"
    ]
    
    found_risks = []
    for risk in risk_keywords:
        if risk in risk_text:
            found_risks.append(risk)
    
    return found_risks

def extract_financial_metrics(data: Dict[str, Any]) -> Dict[str, Any]:
    """æå–è´¢åŠ¡æŒ‡æ ‡"""
    forecast_text = data.get('core_content', {}).get('financial_forecast', '')
    
    import re
    
    metrics = {}
    
    # æå–PEå€¼
    pe_matches = re.findall(r'PE[^0-9]*(\d+\.?\d*)', forecast_text)
    if pe_matches:
        metrics['pe_ratios'] = pe_matches
    
    # æå–å¢é•¿ç‡
    growth_matches = re.findall(r'å¢é•¿[^0-9]*(\d+\.?\d*)%', forecast_text)
    if growth_matches:
        metrics['growth_rates'] = growth_matches
    
    # æå–æ”¶å…¥
    revenue_matches = re.findall(r'æ”¶å…¥[^0-9]*(\d+\.?\d*)äº¿', forecast_text)
    if revenue_matches:
        metrics['revenue_billions'] = revenue_matches
    
    return metrics

def generate_processing_report(data: Dict[str, Any]):
    """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
    
    report = f"""
ğŸ“Š **æ•°æ®å¤„ç†æŠ¥å‘Š**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ **åŸºæœ¬ä¿¡æ¯**
   â€¢ æŠ¥å‘ŠID: {data['report_metadata']['report_id']}
   â€¢ å¤„ç†æ—¶é—´: {data['report_metadata']['processing_time']}
   â€¢ æ•°æ®è´¨é‡: {data['report_metadata']['data_quality_score']}/100

ğŸ“ˆ **å†…å®¹æ‘˜è¦**
   â€¢ ä¸»é¢˜: {data['extracted_data']['basic_info'].get('theme', 'æœªè¯†åˆ«')[:50]}...
   â€¢ ç±»å‹: {data['extracted_data']['basic_info'].get('type', 'æœªè¯†åˆ«')}
   â€¢ æŠ•èµ„å»ºè®®: {data['extracted_data']['basic_info'].get('investment_advice', 'æœªè¯†åˆ«')}

ğŸ“Š **ç»“æ„åŒ–æ•°æ®**
   â€¢ å…³é”®è‚¡ç¥¨: {len(data['extracted_data']['key_stocks'])} åª
   â€¢ é£é™©å› ç´ : {len(data['extracted_data']['risk_factors'])} é¡¹
   â€¢ è´¢åŠ¡æŒ‡æ ‡: {len(data['extracted_data']['financial_metrics'])} ç±»

âœ… **å¤„ç†çŠ¶æ€**
   â€¢ æ ¼å¼ä¿®å¤: {'âœ…' if data['processing_status']['format_fixed'] else 'âŒ'}
   â€¢ å†…å®¹æå–: {'âœ…' if data['processing_status']['content_extracted'] else 'âŒ'}
   â€¢ è‚¡ç¥¨è¯†åˆ«: {'âœ…' if data['processing_status']['stocks_identified'] else 'âŒ'}
   â€¢ åˆ†æå°±ç»ª: {'âœ…' if data['processing_status']['ready_for_analysis'] else 'âŒ'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    """
    
    print(report)
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_file = project_root / "user_data" / "results" / f"processing_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    report_file.parent.mkdir(exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ“„ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

if __name__ == "__main__":
    try:
        complete_data_pipeline()
    except Exception as e:
        print(f"âŒ æµç¨‹æ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc() 