#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†ç ”æŠ¥è„šæœ¬
æ”¯æŒå¯¼å…¥å’Œåˆ†æå¤§é‡ç ”æŠ¥æ•°æ®
"""

import sys
import asyncio
import argparse
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from src.data_processing.processors.report_processor import get_report_processor
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡å¤„ç†ç ”æŠ¥æ•°æ®')
    
    parser.add_argument('input_file', help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['json', 'csv', 'excel', 'txt', 'auto'], 
                       default='auto', help='æ•°æ®æ ¼å¼')
    parser.add_argument('--batch-size', type=int, default=10, 
                       help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--output-dir', default='data/results', 
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--export-format', choices=['json', 'csv'], 
                       default='json', help='å¯¼å‡ºæ ¼å¼')
    parser.add_argument('--config-file', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        print("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†ç ”æŠ¥æ•°æ®")
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input_file}")
        print(f"ğŸ“Š æ•°æ®æ ¼å¼: {args.format}")
        print(f"âš™ï¸ æ‰¹å¤„ç†å¤§å°: {args.batch_size}")
        
        # åŠ è½½é…ç½®
        config = {'batch_size': args.batch_size}
        if args.config_file:
            with open(args.config_file, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                config.update(user_config)
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        processor = get_report_processor(config)
        
        # æ‰¹é‡å¤„ç†
        results = await processor.process_batch_data(
            data_source=args.input_file,
            data_format=args.format
        )
        
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        print("\n" + "="*60)
        print("ğŸ“Š å¤„ç†ç»“æœæ‘˜è¦")
        print("="*60)
        
        summary = results['summary']
        print(f"ğŸ“ˆ æ€»è®¡å¤„ç†: {summary['total_processed']} ç¯‡")
        print(f"âœ… æˆåŠŸå¤„ç†: {summary['successful']} ç¯‡")
        print(f"âŒ å¤„ç†å¤±è´¥: {summary['failed']} ç¯‡")
        print(f"âš ï¸ å¼‚å¸¸æŠ¥å‘Š: {summary['anomalous']} ç¯‡")
        print(f"âœ”ï¸ æ­£å¸¸æŠ¥å‘Š: {summary['normal']} ç¯‡")
        print(f"â±ï¸ å¤„ç†è€—æ—¶: {summary['processing_time']:.2f} ç§’")
        
        if 'reports_per_second' in summary:
            print(f"ğŸš„ å¤„ç†é€Ÿåº¦: {summary['reports_per_second']:.2f} ç¯‡/ç§’")
        
        if 'anomaly_rate' in summary:
            print(f"ğŸ“Š å¼‚å¸¸ç‡: {summary['anomaly_rate']:.2%}")
        
        # å¼‚å¸¸çº§åˆ«åˆ†å¸ƒ
        if results['anomaly_distribution']:
            print(f"\nğŸ“ˆ å¼‚å¸¸çº§åˆ«åˆ†å¸ƒ:")
            for level, count in results['anomaly_distribution'].items():
                print(f"   {level}: {count} ç¯‡")
        
        # æ€§èƒ½ç»Ÿè®¡
        if results['performance_stats']:
            perf = results['performance_stats']
            print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
            print(f"   å¹³å‡å¤„ç†æ—¶é—´: {perf['avg_processing_time']:.3f} ç§’")
            print(f"   æœ€å¿«å¤„ç†æ—¶é—´: {perf['min_processing_time']:.3f} ç§’")
            print(f"   æœ€æ…¢å¤„ç†æ—¶é—´: {perf['max_processing_time']:.3f} ç§’")
        
        # å»ºè®®
        if results['recommendations']:
            print(f"\nğŸ’¡ å¤„ç†å»ºè®®:")
            for i, rec in enumerate(results['recommendations'], 1):
                print(f"   {i}. {rec}")
        
        # å¯¼å‡ºç»“æœ
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"batch_results_{timestamp}.{args.export_format}"
        
        processor.export_results(results, str(output_file), args.export_format)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ˜¾ç¤ºå¼‚å¸¸æŠ¥å‘Šåˆ—è¡¨
        anomalous_reports = [
            r for r in results['detailed_results'] 
            if r['status'] == 'success' and r.get('anomaly_result', {}).get('is_anomalous', False)
        ]
        
        if anomalous_reports:
            print(f"\nâš ï¸ å‘ç° {len(anomalous_reports)} ç¯‡å¼‚å¸¸æŠ¥å‘Š:")
            for report in anomalous_reports[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                anomaly_result = report['anomaly_result']
                print(f"   â€¢ {report['title']} (å¼‚å¸¸åˆ†æ•°: {anomaly_result['overall_anomaly_score']:.3f})")
            
            if len(anomalous_reports) > 10:
                print(f"   ... è¿˜æœ‰ {len(anomalous_reports) - 10} ç¯‡ï¼ˆè¯¦è§å¯¼å‡ºæ–‡ä»¶ï¼‰")
        
        print("\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®æ–‡ä»¶"""
    sample_data = [
        {
            "report_id": "sample_001",
            "title": "æŸç§‘æŠ€å…¬å¸Q3è´¢æŠ¥åˆ†æ",
            "content": """
            æŸç§‘æŠ€å…¬å¸2023å¹´ç¬¬ä¸‰å­£åº¦è´¢åŠ¡æŠ¥å‘Šæ˜¾ç¤ºï¼Œå…¬å¸è¥ä¸šæ”¶å…¥è¾¾åˆ°15.2äº¿å…ƒï¼Œ
            åŒæ¯”å¢é•¿28.5%ã€‚ä½†å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå…¬å¸ç°é‡‘æµé‡å‡ºç°å¼‚å¸¸ï¼š
            
            - ç»è¥æ´»åŠ¨ç°é‡‘æµé‡ä¸ºè´Ÿ3.8äº¿å…ƒï¼Œä¸è¥æ”¶å¢é•¿è¶‹åŠ¿ä¸¥é‡ä¸ç¬¦
            - åº”æ”¶è´¦æ¬¾å¤§å¹…å¢åŠ è‡³12.5äº¿å…ƒï¼Œå è¥æ”¶æ¯”ä¾‹è¾¾82%
            - å­˜è´§å‘¨è½¬ç‡ä»…ä¸º2.1æ¬¡ï¼Œè¿œä½äºè¡Œä¸šå¹³å‡æ°´å¹³
            - åº”ä»˜è´¦æ¬¾å‘¨è½¬å¤©æ•°å¼‚å¸¸å»¶é•¿è‡³180å¤©
            
            æ­¤å¤–ï¼Œå…¬å¸åœ¨æœ¬å­£åº¦çªç„¶å®£å¸ƒå¤§é¢æ”¶è´­è®¡åˆ’ï¼Œä½†æœªæä¾›è¯¦ç»†çš„å°½èŒè°ƒæŸ¥æŠ¥å‘Šã€‚
            å®¡è®¡å¸ˆå¯¹éƒ¨åˆ†å…³è”äº¤æ˜“çš„ä¼šè®¡å¤„ç†æå‡ºäº†å…³æ³¨æ„è§ã€‚
            """,
            "company": "æŸç§‘æŠ€å…¬å¸",
            "industry": "ç§‘æŠ€",
            "report_date": "2023-10-31",
            "analyst": "å¼ ä¸‰"
        },
        {
            "report_id": "sample_002", 
            "title": "ä¼ ç»Ÿåˆ¶é€ ä¼ä¸šè½¬å‹æŠ¥å‘Š",
            "content": """
            æŸä¼ ç»Ÿåˆ¶é€ ä¼ä¸š2023å¹´ä¸šç»©ç¨³å¥ï¼Œè¥ä¸šæ”¶å…¥8.6äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿5.2%ã€‚
            å…¬å¸è´¢åŠ¡æŒ‡æ ‡è¡¨ç°è‰¯å¥½ï¼š
            
            - ç»è¥æ´»åŠ¨ç°é‡‘æµé‡ä¸ºæ­£2.1äº¿å…ƒï¼Œç°é‡‘æµå¥åº·
            - åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡ç¨³å®šåœ¨6.5æ¬¡
            - æ¯›åˆ©ç‡ä¿æŒåœ¨22.8%çš„åˆç†æ°´å¹³
            - è´Ÿå€ºç‡æ§åˆ¶åœ¨45%ä»¥å†…
            
            å…¬å¸æ­£åœ¨æ¨è¿›æ•°å­—åŒ–è½¬å‹ï¼Œç ”å‘æŠ•å…¥å è¥æ”¶æ¯”ä¾‹æå‡è‡³4.2%ã€‚
            ç®¡ç†å±‚è¡¨ç¤ºå°†ç»§ç»­ä¸“æ³¨ä¸»ä¸šå‘å±•ï¼Œå®¡æ…è€ƒè™‘æŠ•èµ„é¡¹ç›®ã€‚
            """,
            "company": "æŸåˆ¶é€ ä¼ä¸š",
            "industry": "åˆ¶é€ ä¸š", 
            "report_date": "2023-10-31",
            "analyst": "æå››"
        }
    ]
    
    # ä¿å­˜ç¤ºä¾‹æ•°æ®
    sample_file = Path("data/sample_reports.json")
    sample_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(sample_file, 'w', encoding='utf-8') as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç¤ºä¾‹æ•°æ®å·²åˆ›å»º: {sample_file}")
    return sample_file


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºç¤ºä¾‹æ•°æ®
    if len(sys.argv) == 1:
        print("ğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
        print("python scripts/batch_process_reports.py <è¾“å…¥æ–‡ä»¶> [é€‰é¡¹]")
        print("\nğŸ“ é€‰é¡¹:")
        print("  --format: æ•°æ®æ ¼å¼ (json/csv/excel/txt/auto)")
        print("  --batch-size: æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 10)")
        print("  --output-dir: è¾“å‡ºç›®å½• (é»˜è®¤: data/results)")
        print("  --export-format: å¯¼å‡ºæ ¼å¼ (json/csv)")
        print("\nğŸ”§ åˆ›å»ºç¤ºä¾‹æ•°æ®å¹¶è¿è¡Œ:")
        
        choice = input("æ˜¯å¦åˆ›å»ºç¤ºä¾‹æ•°æ®å¹¶è¿è¡Œæ¼”ç¤º? (y/N): ")
        if choice.lower() == 'y':
            sample_file = create_sample_data()
            sys.argv = ['batch_process_reports.py', str(sample_file)]
        else:
            sys.exit(0)
    
    asyncio.run(main()) 