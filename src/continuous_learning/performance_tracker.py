"""
æ€§èƒ½è·Ÿè¸ªå™¨
é•¿æœŸè·Ÿè¸ªæ¨¡å‹æ€§èƒ½è¶‹åŠ¿ã€ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šã€æä¾›å†³ç­–æ”¯æŒ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from pathlib import Path
import json
import sqlite3
from dataclasses import dataclass, asdict
from enum import Enum
import logging
from collections import defaultdict, deque
import warnings
import base64
import io

from .feedback_collector import get_feedback_collector
from .model_monitor import get_model_monitor
from .adaptive_learner import get_adaptive_learner
from ..utils.logger import get_logger
from ..utils.config_loader import load_config
from ..utils.file_utils import get_file_manager

logger = get_logger(__name__)

# è®¾ç½®matplotlibä¸­æ–‡æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class ReportType(Enum):
    """æŠ¥å‘Šç±»å‹"""
    DAILY = "daily"
    WEEKLY = "weekly"
    MONTHLY = "monthly"
    QUARTERLY = "quarterly"
    CUSTOM = "custom"


class MetricTrend(Enum):
    """æŒ‡æ ‡è¶‹åŠ¿"""
    IMPROVING = "improving"
    STABLE = "stable"
    DECLINING = "declining"
    VOLATILE = "volatile"
    UNKNOWN = "unknown"


@dataclass
class PerformanceSummary:
    """æ€§èƒ½æ‘˜è¦"""
    period_start: datetime
    period_end: datetime
    total_predictions: int
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    false_positive_rate: float
    average_confidence: float
    error_count: int
    user_satisfaction: float
    
    # è¶‹åŠ¿ä¿¡æ¯
    accuracy_trend: MetricTrend
    performance_change: float
    
    # å¯¹æ¯”åŸºçº¿
    baseline_comparison: Dict[str, float]
    
    # å…³é”®äº‹ä»¶
    adaptations_count: int
    alerts_count: int


@dataclass
class PerformanceReport:
    """æ€§èƒ½æŠ¥å‘Š"""
    report_id: str
    report_type: ReportType
    generated_at: datetime
    period_start: datetime
    period_end: datetime
    
    summary: PerformanceSummary
    detailed_metrics: Dict[str, Any]
    trend_analysis: Dict[str, Any]
    recommendations: List[str]
    
    # å¯è§†åŒ–å›¾è¡¨
    charts: Dict[str, str]  # base64ç¼–ç çš„å›¾ç‰‡
    
    # åŸå§‹æ•°æ®
    raw_data: Optional[Dict[str, Any]] = None


class PerformanceTracker:
    """
    æ€§èƒ½è·Ÿè¸ªå™¨
    
    åŠŸèƒ½ï¼š
    1. é•¿æœŸæ€§èƒ½è·Ÿè¸ª - æ”¶é›†å’Œå­˜å‚¨å†å²æ€§èƒ½æ•°æ®
    2. è¶‹åŠ¿åˆ†æ - è¯†åˆ«æ€§èƒ½å˜åŒ–è¶‹åŠ¿å’Œæ¨¡å¼
    3. åŸºçº¿ç®¡ç† - å»ºç«‹å’Œç»´æŠ¤æ€§èƒ½åŸºçº¿
    4. æŠ¥å‘Šç”Ÿæˆ - è‡ªåŠ¨ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    5. å¯è§†åŒ–åˆ†æ - ç”Ÿæˆæ€§èƒ½è¶‹åŠ¿å›¾è¡¨
    6. å¼‚å¸¸æ£€æµ‹ - è¯†åˆ«æ€§èƒ½å¼‚å¸¸å’Œé€€åŒ–
    7. å¯¹æ¯”åˆ†æ - ä¸åŒæ—¶æœŸæ€§èƒ½å¯¹æ¯”
    8. é¢„æµ‹åˆ†æ - æ€§èƒ½è¶‹åŠ¿é¢„æµ‹
    
    Args:
        config: è·Ÿè¸ªå™¨é…ç½®
        
    Attributes:
        performance_data: æ€§èƒ½æ•°æ®ç¼“å­˜
        reports: ç”Ÿæˆçš„æŠ¥å‘Š
        baselines: æ€§èƒ½åŸºçº¿
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–æ€§èƒ½è·Ÿè¸ªå™¨"""
        self.config = config or {}
        self.file_manager = get_file_manager()
        
        # è·å–å…¶ä»–ç»„ä»¶
        self.feedback_collector = get_feedback_collector()
        self.model_monitor = get_model_monitor()
        self.adaptive_learner = get_adaptive_learner()
        
        # æ•°æ®å­˜å‚¨
        self.data_dir = Path("data/performance_tracking")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.db_path = self.data_dir / "performance_tracking.db"
        self.reports_dir = self.data_dir / "reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        self.charts_dir = self.data_dir / "charts"
        self.charts_dir.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®ç¼“å­˜
        self.performance_data: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.reports: List[PerformanceReport] = []
        
        # æ€§èƒ½åŸºçº¿
        self.baselines = self._load_baselines()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._initialize_database()
        
        # åŠ è½½å†å²æ•°æ®
        self._load_recent_data()
        
        logger.info("æ€§èƒ½è·Ÿè¸ªå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ€§èƒ½å¿«ç…§è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS performance_snapshots (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        accuracy REAL,
                        precision_score REAL,
                        recall REAL,
                        f1_score REAL,
                        false_positive_rate REAL,
                        confidence REAL,
                        prediction_count INTEGER,
                        error_count INTEGER,
                        user_satisfaction REAL,
                        context TEXT
                    )
                ''')
                
                # æ€§èƒ½æŠ¥å‘Šè¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS performance_reports (
                        report_id TEXT PRIMARY KEY,
                        report_type TEXT NOT NULL,
                        generated_at TEXT NOT NULL,
                        period_start TEXT NOT NULL,
                        period_end TEXT NOT NULL,
                        summary_data TEXT NOT NULL,
                        detailed_data TEXT,
                        charts_data TEXT,
                        file_path TEXT
                    )
                ''')
                
                # æ€§èƒ½åŸºçº¿è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS performance_baselines (
                        baseline_id TEXT PRIMARY KEY,
                        metric_name TEXT NOT NULL,
                        baseline_value REAL NOT NULL,
                        confidence_interval TEXT,
                        established_date TEXT NOT NULL,
                        data_points INTEGER,
                        context TEXT
                    )
                ''')
                
                # åˆ›å»ºç´¢å¼•
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_snapshots_timestamp ON performance_snapshots(timestamp)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_reports_generated ON performance_reports(generated_at)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_baselines_metric ON performance_baselines(metric_name)')
                
                conn.commit()
                
            logger.info("æ€§èƒ½è·Ÿè¸ªæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _load_baselines(self) -> Dict[str, float]:
        """åŠ è½½æ€§èƒ½åŸºçº¿"""
        try:
            baselines_file = self.data_dir / "baselines.json"
            if baselines_file.exists():
                with open(baselines_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            # é»˜è®¤åŸºçº¿
            return {
                'accuracy': 0.85,
                'precision': 0.80,
                'recall': 0.75,
                'f1_score': 0.77,
                'false_positive_rate': 0.15,
                'user_satisfaction': 0.70
            }
            
        except Exception as e:
            logger.error(f"åŠ è½½åŸºçº¿å¤±è´¥: {e}")
            return {}
    
    def _load_recent_data(self):
        """åŠ è½½æœ€è¿‘çš„æ€§èƒ½æ•°æ®"""
        try:
            # åŠ è½½æœ€è¿‘30å¤©çš„æ•°æ®
            cutoff_date = datetime.now() - timedelta(days=30)
            
            with sqlite3.connect(self.db_path) as conn:
                query = '''
                    SELECT * FROM performance_snapshots 
                    WHERE timestamp >= ?
                    ORDER BY timestamp
                '''
                
                cursor = conn.cursor()
                cursor.execute(query, (cutoff_date.isoformat(),))
                rows = cursor.fetchall()
                
                for row in rows:
                    timestamp = datetime.fromisoformat(row[1])
                    
                    # å°†æ•°æ®æ·»åŠ åˆ°ç¼“å­˜
                    snapshot = {
                        'timestamp': timestamp,
                        'accuracy': row[2],
                        'precision': row[3],
                        'recall': row[4],
                        'f1_score': row[5],
                        'false_positive_rate': row[6],
                        'confidence': row[7],
                        'prediction_count': row[8],
                        'error_count': row[9],
                        'user_satisfaction': row[10]
                    }
                    
                    for metric, value in snapshot.items():
                        if metric != 'timestamp' and value is not None:
                            self.performance_data[metric].append((timestamp, value))
            
            logger.info(f"åŠ è½½äº† {len(rows)} æ¡å†å²æ€§èƒ½æ•°æ®")
            
        except Exception as e:
            logger.error(f"åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
    
    def capture_performance_snapshot(self, context: Optional[Dict[str, Any]] = None):
        """
        æ•è·æ€§èƒ½å¿«ç…§
        
        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        try:
            timestamp = datetime.now()
            
            # ä»ç›‘æ§å™¨è·å–å½“å‰æŒ‡æ ‡
            current_metrics = self.model_monitor.get_current_metrics()
            
            # ä»åé¦ˆæ”¶é›†å™¨è·å–ç”¨æˆ·æ»¡æ„åº¦
            feedback_stats = self.feedback_collector.calculate_statistics()
            
            # æ„å»ºå¿«ç…§
            snapshot = {
                'timestamp': timestamp,
                'accuracy': self._extract_metric_value(current_metrics, 'accuracy'),
                'precision': self._extract_metric_value(current_metrics, 'precision'),
                'recall': self._extract_metric_value(current_metrics, 'recall'),
                'f1_score': self._extract_metric_value(current_metrics, 'f1_score'),
                'false_positive_rate': self._extract_metric_value(current_metrics, 'error_rate'),
                'confidence': self._extract_metric_value(current_metrics, 'confidence'),
                'prediction_count': current_metrics.get('total_predictions', 0),
                'error_count': current_metrics.get('error_count', 0),
                'user_satisfaction': feedback_stats.user_satisfaction
            }
            
            # æ·»åŠ åˆ°ç¼“å­˜
            for metric, value in snapshot.items():
                if metric != 'timestamp' and value is not None:
                    self.performance_data[metric].append((timestamp, value))
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self._save_snapshot_to_db(snapshot, context)
            
            logger.debug(f"æ€§èƒ½å¿«ç…§å·²æ•è·: {timestamp}")
            
        except Exception as e:
            logger.error(f"æ•è·æ€§èƒ½å¿«ç…§å¤±è´¥: {e}")
    
    def _extract_metric_value(self, metrics: Dict[str, Any], metric_name: str) -> Optional[float]:
        """ä»æŒ‡æ ‡æ•°æ®ä¸­æå–å€¼"""
        try:
            metric_data = metrics.get('metrics', {}).get(metric_name)
            if metric_data:
                return metric_data.get('value')
            return None
        except Exception:
            return None
    
    def _save_snapshot_to_db(self, snapshot: Dict[str, Any], context: Optional[Dict[str, Any]]):
        """ä¿å­˜å¿«ç…§åˆ°æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO performance_snapshots (
                        timestamp, accuracy, precision_score, recall, f1_score,
                        false_positive_rate, confidence, prediction_count,
                        error_count, user_satisfaction, context
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    snapshot['timestamp'].isoformat(),
                    snapshot.get('accuracy'),
                    snapshot.get('precision'),
                    snapshot.get('recall'),
                    snapshot.get('f1_score'),
                    snapshot.get('false_positive_rate'),
                    snapshot.get('confidence'),
                    snapshot.get('prediction_count'),
                    snapshot.get('error_count'),
                    snapshot.get('user_satisfaction'),
                    json.dumps(context) if context else None
                ))
                conn.commit()
                
        except Exception as e:
            logger.error(f"ä¿å­˜å¿«ç…§åˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    def analyze_performance_trend(self, metric_name: str, 
                                 days: int = 30) -> Dict[str, Any]:
        """
        åˆ†ææ€§èƒ½è¶‹åŠ¿
        
        Args:
            metric_name: æŒ‡æ ‡åç§°
            days: åˆ†æå¤©æ•°
            
        Returns:
            Dict: è¶‹åŠ¿åˆ†æç»“æœ
        """
        try:
            # è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            metric_data = self.performance_data.get(metric_name, deque())
            
            # è¿‡æ»¤æ—¶é—´èŒƒå›´
            filtered_data = [
                (timestamp, value) for timestamp, value in metric_data
                if start_time <= timestamp <= end_time
            ]
            
            if len(filtered_data) < 5:
                return {
                    'trend': MetricTrend.UNKNOWN,
                    'message': 'æ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿',
                    'data_points': len(filtered_data)
                }
            
            # æå–å€¼å’Œæ—¶é—´
            values = [value for _, value in filtered_data]
            timestamps = [timestamp for timestamp, _ in filtered_data]
            
            # è®¡ç®—è¶‹åŠ¿
            trend = self._calculate_trend(values)
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values),
                'current': values[-1],
                'change_from_start': values[-1] - values[0],
                'percent_change': ((values[-1] - values[0]) / values[0]) * 100 if values[0] != 0 else 0
            }
            
            # ä¸åŸºçº¿å¯¹æ¯”
            baseline_value = self.baselines.get(metric_name)
            baseline_comparison = None
            if baseline_value:
                baseline_comparison = {
                    'baseline_value': baseline_value,
                    'current_vs_baseline': values[-1] - baseline_value,
                    'percent_vs_baseline': ((values[-1] - baseline_value) / baseline_value) * 100
                }
            
            return {
                'metric_name': metric_name,
                'trend': trend,
                'time_range_days': days,
                'data_points': len(filtered_data),
                'statistics': stats,
                'baseline_comparison': baseline_comparison,
                'data': filtered_data
            }
            
        except Exception as e:
            logger.error(f"åˆ†ææ€§èƒ½è¶‹åŠ¿å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _calculate_trend(self, values: List[float]) -> MetricTrend:
        """è®¡ç®—è¶‹åŠ¿"""
        try:
            if len(values) < 3:
                return MetricTrend.UNKNOWN
            
            # è®¡ç®—çº¿æ€§å›å½’æ–œç‡
            x = np.arange(len(values))
            slope, _ = np.polyfit(x, values, 1)
            
            # è®¡ç®—å˜å¼‚ç³»æ•°
            cv = np.std(values) / np.mean(values) if np.mean(values) != 0 else 0
            
            # åˆ¤æ–­è¶‹åŠ¿
            if cv > 0.2:  # å˜å¼‚ç³»æ•°å¤§äº20%
                return MetricTrend.VOLATILE
            elif slope > 0.01:  # æ­£å‘è¶‹åŠ¿
                return MetricTrend.IMPROVING
            elif slope < -0.01:  # è´Ÿå‘è¶‹åŠ¿
                return MetricTrend.DECLINING
            else:
                return MetricTrend.STABLE
                
        except Exception as e:
            logger.error(f"è®¡ç®—è¶‹åŠ¿å¤±è´¥: {e}")
            return MetricTrend.UNKNOWN
    
    def generate_performance_report(self, report_type: ReportType,
                                  start_date: Optional[datetime] = None,
                                  end_date: Optional[datetime] = None) -> PerformanceReport:
        """
        ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        
        Args:
            report_type: æŠ¥å‘Šç±»å‹
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            PerformanceReport: æ€§èƒ½æŠ¥å‘Š
        """
        try:
            # ç¡®å®šæ—¶é—´èŒƒå›´
            if end_date is None:
                end_date = datetime.now()
            
            if start_date is None:
                if report_type == ReportType.DAILY:
                    start_date = end_date - timedelta(days=1)
                elif report_type == ReportType.WEEKLY:
                    start_date = end_date - timedelta(days=7)
                elif report_type == ReportType.MONTHLY:
                    start_date = end_date - timedelta(days=30)
                elif report_type == ReportType.QUARTERLY:
                    start_date = end_date - timedelta(days=90)
                else:
                    start_date = end_date - timedelta(days=7)
            
            # ç”ŸæˆæŠ¥å‘ŠID
            report_id = f"{report_type.value}_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}"
            
            # æ”¶é›†æ•°æ®
            summary = self._generate_performance_summary(start_date, end_date)
            detailed_metrics = self._collect_detailed_metrics(start_date, end_date)
            trend_analysis = self._analyze_period_trends(start_date, end_date)
            
            # ç”Ÿæˆå»ºè®®
            recommendations = self._generate_recommendations(summary, trend_analysis)
            
            # ç”Ÿæˆå›¾è¡¨
            charts = self._generate_performance_charts(start_date, end_date)
            
            # åˆ›å»ºæŠ¥å‘Š
            report = PerformanceReport(
                report_id=report_id,
                report_type=report_type,
                generated_at=datetime.now(),
                period_start=start_date,
                period_end=end_date,
                summary=summary,
                detailed_metrics=detailed_metrics,
                trend_analysis=trend_analysis,
                recommendations=recommendations,
                charts=charts
            )
            
            # ä¿å­˜æŠ¥å‘Š
            self._save_report(report)
            
            logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ: {report_id}")
            
            return report
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
            raise
    
    def _generate_performance_summary(self, start_date: datetime, 
                                    end_date: datetime) -> PerformanceSummary:
        """ç”Ÿæˆæ€§èƒ½æ‘˜è¦"""
        try:
            # æ”¶é›†æœŸé—´å†…çš„æ‰€æœ‰æ•°æ®ç‚¹
            period_data = {}
            total_predictions = 0
            error_count = 0
            
            for metric_name, data in self.performance_data.items():
                period_values = [
                    value for timestamp, value in data
                    if start_date <= timestamp <= end_date
                ]
                
                if period_values:
                    period_data[metric_name] = {
                        'values': period_values,
                        'mean': np.mean(period_values),
                        'latest': period_values[-1]
                    }
                    
                    if metric_name == 'prediction_count':
                        total_predictions = int(np.sum(period_values))
                    elif metric_name == 'error_count':
                        error_count = int(np.sum(period_values))
            
            # è®¡ç®—ä¸»è¦æŒ‡æ ‡
            accuracy = period_data.get('accuracy', {}).get('mean', 0.0)
            precision = period_data.get('precision', {}).get('mean', 0.0)
            recall = period_data.get('recall', {}).get('mean', 0.0)
            f1_score = period_data.get('f1_score', {}).get('mean', 0.0)
            false_positive_rate = period_data.get('false_positive_rate', {}).get('mean', 0.0)
            average_confidence = period_data.get('confidence', {}).get('mean', 0.0)
            user_satisfaction = period_data.get('user_satisfaction', {}).get('mean', 0.0)
            
            # è®¡ç®—è¶‹åŠ¿
            accuracy_trend = self._calculate_trend(period_data.get('accuracy', {}).get('values', []))
            
            # è®¡ç®—æ€§èƒ½å˜åŒ–
            performance_change = 0.0
            if period_data.get('accuracy', {}).get('values'):
                values = period_data['accuracy']['values']
                if len(values) >= 2:
                    performance_change = values[-1] - values[0]
            
            # ä¸åŸºçº¿å¯¹æ¯”
            baseline_comparison = {}
            for metric_name, baseline_value in self.baselines.items():
                current_value = period_data.get(metric_name, {}).get('mean', 0.0)
                baseline_comparison[metric_name] = current_value - baseline_value
            
            # è·å–é€‚åº”å’Œå‘Šè­¦æ•°é‡
            adaptations_count = 0
            alerts_count = 0
            
            # è¿™é‡Œéœ€è¦ä»å…¶ä»–ç»„ä»¶è·å–å®é™…æ•°æ®
            try:
                learner_summary = self.adaptive_learner.get_learning_summary()
                adaptations_count = learner_summary.get('recent_adaptations', 0)
                
                monitor_summary = self.model_monitor.get_monitoring_summary()
                alerts_count = monitor_summary.get('active_alerts', 0)
            except Exception:
                pass
            
            return PerformanceSummary(
                period_start=start_date,
                period_end=end_date,
                total_predictions=total_predictions,
                accuracy=accuracy,
                precision=precision,
                recall=recall,
                f1_score=f1_score,
                false_positive_rate=false_positive_rate,
                average_confidence=average_confidence,
                error_count=error_count,
                user_satisfaction=user_satisfaction,
                accuracy_trend=accuracy_trend,
                performance_change=performance_change,
                baseline_comparison=baseline_comparison,
                adaptations_count=adaptations_count,
                alerts_count=alerts_count
            )
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€§èƒ½æ‘˜è¦å¤±è´¥: {e}")
            raise
    
    def _collect_detailed_metrics(self, start_date: datetime, 
                                end_date: datetime) -> Dict[str, Any]:
        """æ”¶é›†è¯¦ç»†æŒ‡æ ‡"""
        try:
            detailed = {}
            
            # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡çš„è¯¦ç»†ç»Ÿè®¡
            for metric_name, data in self.performance_data.items():
                period_values = [
                    value for timestamp, value in data
                    if start_date <= timestamp <= end_date
                ]
                
                if period_values:
                    detailed[metric_name] = {
                        'count': len(period_values),
                        'mean': float(np.mean(period_values)),
                        'std': float(np.std(period_values)),
                        'min': float(np.min(period_values)),
                        'max': float(np.max(period_values)),
                        'median': float(np.median(period_values)),
                        'q25': float(np.percentile(period_values, 25)),
                        'q75': float(np.percentile(period_values, 75)),
                        'trend': self._calculate_trend(period_values).value
                    }
            
            return detailed
            
        except Exception as e:
            logger.error(f"æ”¶é›†è¯¦ç»†æŒ‡æ ‡å¤±è´¥: {e}")
            return {}
    
    def _analyze_period_trends(self, start_date: datetime, 
                             end_date: datetime) -> Dict[str, Any]:
        """åˆ†ææœŸé—´è¶‹åŠ¿"""
        try:
            trends = {}
            
            # åˆ†ææ¯ä¸ªæŒ‡æ ‡çš„è¶‹åŠ¿
            for metric_name in ['accuracy', 'precision', 'recall', 'f1_score']:
                trend_result = self.analyze_performance_trend(
                    metric_name, 
                    days=(end_date - start_date).days
                )
                trends[metric_name] = trend_result
            
            return trends
            
        except Exception as e:
            logger.error(f"åˆ†ææœŸé—´è¶‹åŠ¿å¤±è´¥: {e}")
            return {}
    
    def _generate_recommendations(self, summary: PerformanceSummary, 
                                trends: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        try:
            # åŸºäºå‡†ç¡®ç‡è¶‹åŠ¿çš„å»ºè®®
            if summary.accuracy_trend == MetricTrend.DECLINING:
                recommendations.append("âš ï¸ æ£€æµ‹å‡†ç¡®ç‡å‘ˆä¸‹é™è¶‹åŠ¿ï¼Œå»ºè®®é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–è°ƒæ•´æ£€æµ‹é˜ˆå€¼")
            
            # åŸºäºè¯¯æŠ¥ç‡çš„å»ºè®®
            if summary.false_positive_rate > 0.2:
                recommendations.append("ğŸ” è¯¯æŠ¥ç‡è¾ƒé«˜ï¼Œå»ºè®®æé«˜æ£€æµ‹é˜ˆå€¼æˆ–ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹")
            
            # åŸºäºç”¨æˆ·æ»¡æ„åº¦çš„å»ºè®®
            if summary.user_satisfaction < 0.7:
                recommendations.append("ğŸ‘¥ ç”¨æˆ·æ»¡æ„åº¦è¾ƒä½ï¼Œå»ºè®®æ”¶é›†æ›´å¤šç”¨æˆ·åé¦ˆå¹¶æ”¹è¿›æ¨¡å‹")
            
            # åŸºäºåŸºçº¿å¯¹æ¯”çš„å»ºè®®
            accuracy_diff = summary.baseline_comparison.get('accuracy', 0)
            if accuracy_diff < -0.05:
                recommendations.append("ğŸ“Š å‡†ç¡®ç‡ä½äºåŸºçº¿ï¼Œå»ºè®®è¿›è¡Œæ¨¡å‹è¯Šæ–­å’Œä¼˜åŒ–")
            
            # åŸºäºè‡ªé€‚åº”å­¦ä¹ çš„å»ºè®®
            if summary.adaptations_count == 0:
                recommendations.append("ğŸ”„ å»ºè®®å¯ç”¨è‡ªé€‚åº”å­¦ä¹ åŠŸèƒ½ä»¥æŒç»­ä¼˜åŒ–æ¨¡å‹æ€§èƒ½")
            
            # åŸºäºå‘Šè­¦çš„å»ºè®®
            if summary.alerts_count > 0:
                recommendations.append(f"ğŸš¨ å½“å‰æœ‰ {summary.alerts_count} ä¸ªæ´»è·ƒå‘Šè­¦ï¼Œå»ºè®®åŠæ—¶å¤„ç†")
            
            # å¦‚æœæ²¡æœ‰å…·ä½“å»ºè®®ï¼Œç»™å‡ºä¸€èˆ¬æ€§å»ºè®®
            if not recommendations:
                recommendations.append("âœ… æ¨¡å‹æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ç›‘æ§å¹¶å®šæœŸè¯„ä¼°")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå»ºè®®å¤±è´¥: {e}")
            recommendations.append("â— å»ºè®®ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥ç³»ç»ŸçŠ¶æ€")
        
        return recommendations
    
    def _generate_performance_charts(self, start_date: datetime, 
                                   end_date: datetime) -> Dict[str, str]:
        """ç”Ÿæˆæ€§èƒ½å›¾è¡¨"""
        charts = {}
        
        try:
            # è®¾ç½®å›¾è¡¨æ ·å¼
            plt.style.use('seaborn-v0_8')
            
            # 1. å‡†ç¡®ç‡è¶‹åŠ¿å›¾
            charts['accuracy_trend'] = self._create_trend_chart(
                'accuracy', start_date, end_date, 'å‡†ç¡®ç‡è¶‹åŠ¿'
            )
            
            # 2. å¤šæŒ‡æ ‡å¯¹æ¯”å›¾
            charts['metrics_comparison'] = self._create_multi_metrics_chart(
                start_date, end_date
            )
            
            # 3. ç”¨æˆ·æ»¡æ„åº¦å›¾
            charts['user_satisfaction'] = self._create_trend_chart(
                'user_satisfaction', start_date, end_date, 'ç”¨æˆ·æ»¡æ„åº¦è¶‹åŠ¿'
            )
            
            # 4. æ€§èƒ½åˆ†å¸ƒå›¾
            charts['performance_distribution'] = self._create_distribution_chart(
                start_date, end_date
            )
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€§èƒ½å›¾è¡¨å¤±è´¥: {e}")
        
        return charts
    
    def _create_trend_chart(self, metric_name: str, start_date: datetime,
                          end_date: datetime, title: str) -> str:
        """åˆ›å»ºè¶‹åŠ¿å›¾è¡¨"""
        try:
            # è·å–æ•°æ®
            data = self.performance_data.get(metric_name, deque())
            period_data = [
                (timestamp, value) for timestamp, value in data
                if start_date <= timestamp <= end_date
            ]
            
            if not period_data:
                return ""
            
            timestamps, values = zip(*period_data)
            
            # åˆ›å»ºå›¾è¡¨
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(timestamps, values, linewidth=2, marker='o', markersize=4)
            ax.set_title(title, fontsize=16, fontweight='bold')
            ax.set_xlabel('æ—¶é—´', fontsize=12)
            ax.set_ylabel(metric_name.replace('_', ' ').title(), fontsize=12)
            ax.grid(True, alpha=0.3)
            
            # æ·»åŠ åŸºçº¿
            if metric_name in self.baselines:
                baseline = self.baselines[metric_name]
                ax.axhline(y=baseline, color='red', linestyle='--', alpha=0.7, label='åŸºçº¿')
                ax.legend()
            
            # æ ¼å¼åŒ–xè½´
            fig.autofmt_xdate()
            
            # è½¬æ¢ä¸ºbase64
            return self._fig_to_base64(fig)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè¶‹åŠ¿å›¾è¡¨å¤±è´¥: {e}")
            return ""
    
    def _create_multi_metrics_chart(self, start_date: datetime, 
                                  end_date: datetime) -> str:
        """åˆ›å»ºå¤šæŒ‡æ ‡å¯¹æ¯”å›¾"""
        try:
            metrics = ['accuracy', 'precision', 'recall', 'f1_score']
            
            fig, ax = plt.subplots(figsize=(14, 8))
            
            for metric in metrics:
                data = self.performance_data.get(metric, deque())
                period_data = [
                    (timestamp, value) for timestamp, value in data
                    if start_date <= timestamp <= end_date
                ]
                
                if period_data:
                    timestamps, values = zip(*period_data)
                    ax.plot(timestamps, values, label=metric.replace('_', ' ').title(), 
                           linewidth=2, marker='o', markersize=3)
            
            ax.set_title('æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”', fontsize=16, fontweight='bold')
            ax.set_xlabel('æ—¶é—´', fontsize=12)
            ax.set_ylabel('åˆ†æ•°', fontsize=12)
            ax.legend(loc='best')
            ax.grid(True, alpha=0.3)
            ax.set_ylim(0, 1)
            
            fig.autofmt_xdate()
            
            return self._fig_to_base64(fig)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå¤šæŒ‡æ ‡å¯¹æ¯”å›¾å¤±è´¥: {e}")
            return ""
    
    def _create_distribution_chart(self, start_date: datetime, 
                                 end_date: datetime) -> str:
        """åˆ›å»ºæ€§èƒ½åˆ†å¸ƒå›¾"""
        try:
            # è·å–å‡†ç¡®ç‡æ•°æ®
            data = self.performance_data.get('accuracy', deque())
            period_values = [
                value for timestamp, value in data
                if start_date <= timestamp <= end_date
            ]
            
            if not period_values:
                return ""
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
            
            # ç›´æ–¹å›¾
            ax1.hist(period_values, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
            ax1.set_title('å‡†ç¡®ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            ax1.set_xlabel('å‡†ç¡®ç‡', fontsize=12)
            ax1.set_ylabel('é¢‘æ¬¡', fontsize=12)
            ax1.grid(True, alpha=0.3)
            
            # ç®±çº¿å›¾
            ax2.boxplot(period_values, vert=True, patch_artist=True,
                       boxprops=dict(facecolor='lightblue', alpha=0.7))
            ax2.set_title('å‡†ç¡®ç‡ç®±çº¿å›¾', fontsize=14, fontweight='bold')
            ax2.set_ylabel('å‡†ç¡®ç‡', fontsize=12)
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            return self._fig_to_base64(fig)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºåˆ†å¸ƒå›¾å¤±è´¥: {e}")
            return ""
    
    def _fig_to_base64(self, fig) -> str:
        """å°†matplotlibå›¾è¡¨è½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        try:
            buffer = io.BytesIO()
            fig.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            
            # è½¬æ¢ä¸ºbase64
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            plt.close(fig)  # å…³é—­å›¾è¡¨é‡Šæ”¾å†…å­˜
            
            return f"data:image/png;base64,{img_base64}"
            
        except Exception as e:
            logger.error(f"å›¾è¡¨è½¬æ¢å¤±è´¥: {e}")
            plt.close(fig)
            return ""
    
    def _save_report(self, report: PerformanceReport):
        """ä¿å­˜æŠ¥å‘Š"""
        try:
            # ä¿å­˜åˆ°æ•°æ®åº“
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT OR REPLACE INTO performance_reports (
                        report_id, report_type, generated_at, period_start, period_end,
                        summary_data, detailed_data, charts_data, file_path
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    report.report_id,
                    report.report_type.value,
                    report.generated_at.isoformat(),
                    report.period_start.isoformat(),
                    report.period_end.isoformat(),
                    json.dumps(asdict(report.summary), default=str),
                    json.dumps(report.detailed_metrics),
                    json.dumps(report.charts),
                    None  # æ–‡ä»¶è·¯å¾„æš‚æ—¶ä¸ºç©º
                ))
                conn.commit()
            
            # æ·»åŠ åˆ°æŠ¥å‘Šåˆ—è¡¨
            self.reports.append(report)
            
            # ä¿æŒæœ€è¿‘50ä¸ªæŠ¥å‘Š
            if len(self.reports) > 50:
                self.reports = self.reports[-50:]
                
        except Exception as e:
            logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    
    def get_performance_dashboard_data(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ä»ªè¡¨æ¿æ•°æ®"""
        try:
            # è·å–æœ€è¿‘7å¤©çš„æ•°æ®
            recent_summary = self._generate_performance_summary(
                datetime.now() - timedelta(days=7),
                datetime.now()
            )
            
            # è·å–è¶‹åŠ¿æ•°æ®
            trends = {}
            for metric in ['accuracy', 'precision', 'recall', 'f1_score']:
                trends[metric] = self.analyze_performance_trend(metric, days=7)
            
            # è·å–æœ€è¿‘çš„æŠ¥å‘Š
            recent_reports = sorted(self.reports, key=lambda x: x.generated_at, reverse=True)[:5]
            
            return {
                'summary': asdict(recent_summary),
                'trends': trends,
                'recent_reports': [
                    {
                        'report_id': r.report_id,
                        'report_type': r.report_type.value,
                        'generated_at': r.generated_at.isoformat(),
                        'period_start': r.period_start.isoformat(),
                        'period_end': r.period_end.isoformat()
                    }
                    for r in recent_reports
                ],
                'system_health': self.model_monitor.get_current_metrics().get('system_health', 'unknown'),
                'data_freshness': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»ªè¡¨æ¿æ•°æ®å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def get_tracking_summary(self) -> Dict[str, Any]:
        """è·å–è·Ÿè¸ªæ‘˜è¦"""
        try:
            return {
                'data_points_cached': sum(len(data) for data in self.performance_data.values()),
                'metrics_tracked': list(self.performance_data.keys()),
                'reports_generated': len(self.reports),
                'baselines_configured': len(self.baselines),
                'database_path': str(self.db_path),
                'charts_directory': str(self.charts_dir),
                'last_snapshot': max([
                    max(data, key=lambda x: x[0])[0] if data else datetime.min
                    for data in self.performance_data.values()
                ], default=datetime.min).isoformat() if any(self.performance_data.values()) else None
            }
            
        except Exception as e:
            logger.error(f"è·å–è·Ÿè¸ªæ‘˜è¦å¤±è´¥: {e}")
            return {'error': str(e)}


# å…¨å±€æ€§èƒ½è·Ÿè¸ªå™¨å®ä¾‹
_global_performance_tracker = None


def get_performance_tracker() -> PerformanceTracker:
    """
    è·å–å…¨å±€æ€§èƒ½è·Ÿè¸ªå™¨å®ä¾‹
    
    Returns:
        PerformanceTracker: è·Ÿè¸ªå™¨å®ä¾‹
    """
    global _global_performance_tracker
    
    if _global_performance_tracker is None:
        _global_performance_tracker = PerformanceTracker()
    
    return _global_performance_tracker


if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    print("æ€§èƒ½è·Ÿè¸ªå™¨æµ‹è¯•:")
    
    # åˆ›å»ºè·Ÿè¸ªå™¨
    tracker = PerformanceTracker()
    
    # æ•è·æ€§èƒ½å¿«ç…§
    tracker.capture_performance_snapshot()
    
    # åˆ†æè¶‹åŠ¿
    trend = tracker.analyze_performance_trend('accuracy', days=7)
    print(f"å‡†ç¡®ç‡è¶‹åŠ¿: {trend}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = tracker.generate_performance_report(ReportType.WEEKLY)
    print(f"æŠ¥å‘Šç”Ÿæˆ: {report.report_id}")
    
    # è·å–ä»ªè¡¨æ¿æ•°æ®
    dashboard = tracker.get_performance_dashboard_data()
    print(f"ä»ªè¡¨æ¿æ•°æ®: {dashboard}")
    
    # è·å–æ‘˜è¦
    summary = tracker.get_tracking_summary()
    print(f"è·Ÿè¸ªæ‘˜è¦: {summary}") 